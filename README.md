# MarkNull

This repository contains the implementation of **MarkNull: Model-Agnostic Watermark Removal in AI-Generated Images via On-Manifold Latent Manipulation**.

## ðŸ’¡ Overview

MarkNull consists of two components:

- **MarkNull**: An optimization-based adversarial attack in the latent space.
- **MarkNull-A**: An amortized variant using a trained neural network for efficient watermark removal.


## Installation (requirements.txt)

We recommend using a fresh conda environment and installing Python dependencies via `requirements.txt`.

```bash
# create and activate a conda environment
conda create -n marknull python=3.10 -y
conda activate marknull

# upgrade pip
python -m pip install -U pip

# install dependencies
python -m pip install -r requirements.txt
```

## Watermarked Image Preparation
To facilitate deployment of watermarking schemes, readers may refer to the original implementations of all baseline methods cited in our manuscript, or alternatively use the benchmark toolkit at https://github.com/THU-BPM/MarkDiffusion. After generating watermarked images in batch, please store them under ./Watermarked/ and then run our attack pipeline on this directory.

We provide Watermarked/SD2.1_GS/ as a concrete example, which contains watermarked images produced by the Gaussian Shading method under Stable Diffusion 2.1.


## Data Layout

We organize images using the following directory structure:

- `./Watermarked/`: **clean, watermarked** images generated by different watermarking schemes.
- `./Attacked/`: **attacked (watermark-suppressed)** images produced by our attack pipeline.

### Path Conventions

- Watermarked images: `./Watermarked/<SUBSET_NAME>/`
- Attacked images: `./Attacked/<ATTACK_NAME>/<SUBSET_NAME>/`

Here, `<ATTACK_NAME>` denotes the attack method, and `<SUBSET_NAME>` typically encodes the target model and watermarking scheme (e.g., `SD2.1_GS` indicates Gaussian Shading watermarked images under Stable Diffusion 2.1).

### Example

```text
Watermarked/
  SD2.1_GS/
    0.png
    1.png

Attacked/
  MarkNull/
    SD2.1_GS/
      0.png
      1.png
```

## Attack

### 1. Run MarkNull (Optimization-Based)
```bash
python MarkNull_attack.py
```
### 2. Run MarkNull-A (Amortized Variant)

MarkNull-A is an amortized variant of MarkNull that performs one-pass watermark suppression via a trained WRN.

#### Option A: Train MarkNull-A
Train the WRN from scratch:

```bash
python train.py
```

#### Option B: Use the Pretrained Weights
Download the pretrained checkpoint and extract it to ./MarkNull-A/:

**Download weights**
```bash
https://github.com/asdasewq/MarkNull/releases
7z x trained_model.7z -o./MarkNull-A
```
#### Use MarkNull-A to Attack
```bash
python MarkNull_A_attack.py
```

### 3. Proposed Defense Strategy
`defense.py` implements a potential mitigation strategy proposed in the manuscript. 
```bash
python defense.py
```
